{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\judoc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import autogen\n",
    "from autogen import register_function, AssistantAgent, UserProxyAgent\n",
    "from autogen.agentchat.contrib.retrieve_assistant_agent import RetrieveAssistantAgent\n",
    "from autogen.agentchat.contrib.qdrant_retrieve_user_proxy_agent import QdrantRetrieveUserProxyAgent\n",
    "from autogen.agentchat.contrib.web_surfer import WebSurferAgent\n",
    "from chromadb.utils import embedding_functions\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from qdrant_client import QdrantClient\n",
    "from ARGO import ArgoWrapper\n",
    "from CustomLLMAutogen2 import ARGO_LLM\n",
    "from typing import Dict, List, Any\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All available models\n",
    "config_list = [\n",
    "        {\n",
    "            'model': 'gpt-3.5-turbo-16k',\n",
    "            'tags': ['gpt3.5']\n",
    "        },\n",
    "        {\n",
    "            'model': 'Argo',\n",
    "            'api_type': 'argo',\n",
    "            'argo_client': ARGO_LLM(argo=ArgoWrapper,model_type='gpt4', temperature = 0.3),\n",
    "            'tags': ['argo']\n",
    "        },\n",
    "        {\n",
    "            'model': 'NA',\n",
    "            'api_key': 'NA',\n",
    "            'base_url': 'http://140.221.70.43:5005/llm/v1',\n",
    "            'tags': ['local']\n",
    "        }\n",
    "]\n",
    "# Filters the models based on the tags. Filters models\n",
    "filter_dict = {'tags': ['gpt3.5']}\n",
    "config_list = autogen.filter_config(config_list, filter_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'config_list': [{'model': 'gpt-3.5-turbo-16k', 'tags': ['gpt3.5']}],\n",
       " 'cache_seed': None,\n",
       " 'timeout': 600,\n",
       " 'seed': 44,\n",
       " 'temperature': 0.2}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sets up configuration for agents\n",
    "llm_config = {\n",
    "    \"config_list\": config_list, \n",
    "    \"cache_seed\": None, # Ensures differing responses\n",
    "    \"timeout\": 600,\n",
    "    \"seed\": 44,\n",
    "    \"temperature\": 0.2, # Temperature max is 2\n",
    "}\n",
    "llm_config_gen = {\n",
    "    \"config_list\": \n",
    "    [\n",
    "        {\n",
    "            'model': 'gpt-4-turbo',\n",
    "        }\n",
    "    ], \n",
    "    \"cache_seed\": None, # Ensures differing responses\n",
    "    \"timeout\": 600,\n",
    "    \"seed\": 44,\n",
    "    \"temperature\": 1.0, # Temperature max is 2\n",
    "    \"response_format\": { \"type\": \"json_object\" },\n",
    "}\n",
    "llm_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "googleai_embedding_function= embedding_functions.GoogleGenerativeAiEmbeddingFunction(api_key = os.environ[\"GOOGLE_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(separators=[\"\\n\\n\", \"\\n\", \"\\r\", \"\\t\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def termination_msg(x):\n",
    "    return isinstance(x, dict) and \"TERMINATE\" == str(x.get(\"content\", \"\"))[-9:].upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = f'''For each paper, generate 3 unique and extremely difficult to answer multiple choice questions with 5 choices each.\n",
    "The answerer does not have access to the paper, you cannot require context for the question.\n",
    "These should be general knowledge questions with supporting evidence from the paper.\n",
    "All context required to answer the question must be provided within the question statement.\n",
    "The question statement cannot include 'in this study', 'in this paper', 'according to the paper', etc.\n",
    "There should be exactly one correct answer.\n",
    "The incorrect answers must be difficult to distinguish from the correct answer, however they cannot be correct.\n",
    "The incorrect answers are 'distractors' that are designed to be confuse the large language model that is answering the question.\n",
    "'''\n",
    "\n",
    "# problem = f'''For every paper in docs, generate 3 unique and extremely confusing to answer multiple choice questions with 5 choices each.\n",
    "# Each question and its choices are designed to trick the answerer.\n",
    "# The answerer does not have access to the paper, you cannot require context for the question.\n",
    "# These should be general knowledge questions with supporting evidence from the paper.\n",
    "# All context required to answer the question must be provided within the question statement.\n",
    "# There should be exactly one correct answer.\n",
    "# The incorrect answers must be difficult to distinguish from the correct answer, however they cannot be correct.\n",
    "# The incorrect answers are 'distractors' that are designed to be confuse the large language model that is answering the question.\n",
    "# '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCHEMA = {\n",
    "  \"question\": \"The generated question\",\n",
    "  \"correct_answer\": \"The correct answer\",\n",
    "  \"distractors\": [\n",
    "    \"Incorrect answer #1\", \"Incorrect answer #2\", \"Incorrect Answer #3\", \"Incorrect Answer #4\"\n",
    "  ],\n",
    "  \"skills\": f'''Choose the necessary skills for answering the question using at least one of the following options \n",
    "  {[\"Generalization\", \"Basic comprehension\", \"Summarization\", \"Interpolation/extrapolation\", \"Cross-domain application\", \"Reasoning\", \"General knowledge\", \"Fundamental domain science concepts\", \"Understanding identifiers/notation\", \"Understanding evolution of ideas\"]}\n",
    "  Must be in the form of a {list}''',\n",
    "  \"domains\": f'''Choose the most applicable domains for the question using at least one of the following options\n",
    "  {[\"physics\", \"material science\", \"biology\", \"chemistry\", \"computer science\", \"mathematics\", \"climate\"]}\n",
    "  Must be in the form of a {list}''',\n",
    "  \"difficulty\": \"Choose the difficulty of the question using one of the following options ['easy', 'medium', 'hard'] \",\n",
    "  \"doi\": \"Identify the digital object identifier (DOI) of the paper and provide it here. It will be the link of the form doi.org\",\n",
    "  \"author\": {\n",
    "      \"name\": \"Jose A. Tandoc\",\n",
    "      \"affiliation\": \"Jose A. Tandoc\",\n",
    "      \"position\": \"Student\",\n",
    "      \"orcid\": \"NA\"\n",
    "  },\n",
    "  \"support\": \"\",\n",
    "  \"comments\": \"generated question\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initiate_RAG_agent(docs: List[str], collection: str):\n",
    "    retrieval_assistant = QdrantRetrieveUserProxyAgent(\n",
    "        name=\"assistant\",\n",
    "        human_input_mode=\"NEVER\",\n",
    "        default_auto_reply=\"Reply `TERMINATE` if the task is done.\",\n",
    "        # max_consecutive_auto_reply=10,\n",
    "        retrieve_config={\n",
    "            \"task\": \"qa\",\n",
    "            \"docs_path\": docs,\n",
    "            \"custom_text_split_function\": text_splitter.split_text,\n",
    "            \"embedding_funcion\": googleai_embedding_function,\n",
    "            \"client\": QdrantClient(url=\"https://7f9bbc68-cbea-48e0-9841-2dd23f878d28.us-east4-0.gcp.cloud.qdrant.io\", api_key= os.environ[\"QDRANT_API_KEY\"]),\n",
    "            \"collection_name\": collection,\n",
    "            \"get_or_create\": True,\n",
    "        },\n",
    "        code_execution_config=False,\n",
    "        description=\"Assistant who has extra content retrieval power for solving difficult problems.\",\n",
    "    )\n",
    "    return retrieval_assistant\n",
    "\n",
    "expert = AssistantAgent(\n",
    "    \"Expert\",\n",
    "    system_message=f'''You are an expert on {problem} Assist in answering the problem. Then, put the information in a list using the following schema: {SCHEMA}. Follow the instructions of the SCHEMA.\n",
    "    You should return a python {Dict}: {{'question1': SCHEMA, 'question2': SCHEMA, 'question3': SCHEMA}}. Do not change the author, question, affiliation, or comments fields. This response must be a JSON object.\n",
    "    Reply 'TERMINATE' in the end when everything is done.''',\n",
    "    llm_config=llm_config_gen,\n",
    "    human_input_mode=\"NEVER\",  # Never ask for human input.\n",
    "    description=\"Expert in question generation.\",\n",
    ")\n",
    "\n",
    "format_verifier = autogen.ConversableAgent(\n",
    "    \"format_verifier\",\n",
    "    system_message=f'''You are a format verifier that ensures that the expert's response is a python dictionary of dictionaries: {Dict[Dict, Any]}. \n",
    "    Reply 'VALID' if the format is a singular JSON object.\n",
    "    Otherwise, reply 'WRONG' and prompt expert for a new format.''',\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",  # Never ask for human input.\n",
    "    description=\"Verifier who can verify the correctness of expert's questions.\",\n",
    ")\n",
    "\n",
    "generality_verifier = autogen.ConversableAgent(\n",
    "    \"generality_verifier\",\n",
    "    system_message=f'''You are a generality verifier that ensures that a given question is not paper-specific. That is, it can be answered without reading the paper.\n",
    "    If the question is too specific, you prompt the expert for another question.\n",
    "    Reply 'VALID' if the response is general enough to be answered without reading the paper and pass the JSON object to the question_generation_automator. Otherwise, reply 'WRONG' and provide feedback on how to improve the question.''',\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    description=\"Generality Verifier who ensures that each question is general enough to be answered without reading the given paper.\",\n",
    ")\n",
    "\n",
    "automator = AssistantAgent(\n",
    "    'question_generation_automator',\n",
    "    system_message=f'''DO NOT UPDATE CONTEXT. You are an automator that takes the JSON object produced by the expert and makes a function call to the add_questions function.\n",
    "    Reply 'TERMINATE' in the end when everything is done.''',\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    description=\"Automator utilizes functions to automate the process of generating questions.\",\n",
    ")\n",
    "\n",
    "user_proxy = autogen.ConversableAgent(\n",
    "    name=\"User\",\n",
    "    system_message=f'''You are a user that can execute the add_questions function to add the generated questions to the CSV file.''',\n",
    "    is_termination_msg=termination_msg,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    code_execution_config=False,\n",
    "    description=\"The proxy that adds the question to the CSV file using the add_questions function\"\n",
    ")\n",
    "\n",
    "# web_surfer = WebSurferAgent(\n",
    "#     \"web_surfer\",\n",
    "#     system_message=f'''You are a web surfer that can find the DOI of a paper using the paper's title.\n",
    "#     Reply 'TERMINATE' in the end when everything is done''',\n",
    "#     llm_config=llm_config,\n",
    "#     summarizer_llm_config=llm_config,\n",
    "#     browser_config={\"viewport_size\": 4096, \"bing_api_key\": os.environ[\"BING_API_KEY\"]},\n",
    "#     description=\"Web Surfer who can search the web for information.\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_question(question: str, correct_answer: str, distractors: List[str], skills: str, domains: str, difficulty: str, doi: str, author: str, comments: str, affiliation: str, position: str) -> str:\n",
    "    cur = pd.DataFrame([{\n",
    "        \"question\": question,\n",
    "        \"correct_answer\": correct_answer,\n",
    "        \"distractors\": distractors,\n",
    "        \"skills\": skills,\n",
    "        \"domains\": domains,\n",
    "        \"difficulty\": difficulty,\n",
    "        \"doi\": doi,\n",
    "        \"author\": author,\n",
    "        \"comments\": comments,\n",
    "        \"affiliation\": affiliation,\n",
    "        \"position\": position,\n",
    "    }])\n",
    "    if os.path.exists(r\"generatedQuestions/generated_questions.csv\"):\n",
    "        df = pd.read_csv(r\"generatedQuestions/generated_questions.csv\")\n",
    "        df = pd.concat([df, cur])\n",
    "        df.to_csv(r\"generatedQuestions/generated_questions.csv\", index=False)\n",
    "    else:\n",
    "        cur.to_csv(r\"generatedQuestions/generated_questions.csv\", index=False)\n",
    "    return \"Question added to the CSV file.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_questions(question1: Dict, question2: Dict, question3: Dict) -> str:\n",
    "    q1 = pd.DataFrame([question1])\n",
    "    q2 = pd.DataFrame([question2])\n",
    "    q3 = pd.DataFrame([question3])\n",
    "    cur = pd.concat([q1, q2, q3], ignore_index=True)\n",
    "    if os.path.exists(r\"generatedQuestions/generated_questions.csv\"):\n",
    "        cur.to_csv(r\"generatedQuestions/generated_questions.csv\", mode='a', header=False, index=False)\n",
    "    else:\n",
    "        cur.to_csv(r\"generatedQuestions/generated_questions.csv\", mode='w', index=False)\n",
    "    return 'Finished'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "register_function(\n",
    "    add_questions,\n",
    "    caller=automator,\n",
    "    executor=user_proxy,\n",
    "    name=\"add_questions\",\n",
    "    description=\"Adds all generated questions to the CSV file. Arguments required: question1=Dict, question2=Dict, question3=Dict\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = glob.glob('../papers/*.pdf')\n",
    "doc_count = len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _reset_agents(retrieval_assistant):\n",
    "    retrieval_assistant.reset()\n",
    "    expert.reset()\n",
    "    # format_verifier.reset()\n",
    "    # generality_verifier.reset()\n",
    "    automator.reset()\n",
    "    user_proxy.reset()\n",
    "    #web_surfer.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to create collection.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-11 10:03:38,438 - autogen.agentchat.contrib.qdrant_retrieve_user_proxy_agent - INFO - Found 21 chunks.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mAdding content of doc 20 to context.\u001b[0m\n",
      "\u001b[32mAdding content of doc 19 to context.\u001b[0m\n",
      "\u001b[32mAdding content of doc 12 to context.\u001b[0m\n",
      "\u001b[33massistant\u001b[0m (to chat_manager):\n",
      "\n",
      "You're a retrieve augmented chatbot. You answer user's questions based on your own knowledge and the\n",
      "context provided by the user.\n",
      "If you can't answer the question with or without the current context, you should reply exactly `UPDATE CONTEXT`.\n",
      "You must give as short an answer as possible.\n",
      "\n",
      "User's question is: For each paper, generate 3 unique and extremely difficult to answer multiple choice questions with 5 choices each.\n",
      "The answerer does not have access to the paper, you cannot require context for the question.\n",
      "These should be general knowledge questions with supporting evidence from the paper.\n",
      "All context required to answer the question must be provided within the question statement.\n",
      "The question statement cannot include 'in this study', 'in this paper', 'according to the paper', etc.\n",
      "There should be exactly one correct answer.\n",
      "The incorrect answers must be difficult to distinguish from the correct answer, however they cannot be correct.\n",
      "The incorrect answers are 'distractors' that are designed to be confuse the large language model that is answering the question.\n",
      "\n",
      "\n",
      "Context is: anonymously, reproducing the same conditions in future studies should be relatively easy, assuming care is taken to remain anon ymous.\n",
      "Randomization The players and order in which we played against them was determined by the matchmaking algorithm that Blizzard employs to crea te \n",
      "matches in their online service, which was designed many years before our study, and which the authors of this manuscript had n o control \n",
      "over. Such system is solely based on the skill level of players, and is thus random and the authors of this manuscript were bli nd to group \n",
      "allocation.\n",
      "Blinding The authors were blind to group allocation. See \"Randomization\".\n",
      "Reporting for specific materials, systems and methods\n",
      "We require information from authors about some types of materials, experimental systems and methods used in many studies. Here,  indicate whether each material, \n",
      "system or method listed is relevant to your study. If you are not sure if a list item applies to your research, read the approp riate section before selecting a response. \n",
      "Materials & experimental systems\n",
      "n/a Involved in the study\n",
      "Antibodies\n",
      "Eukaryotic cell lines\n",
      "Palaeontology\n",
      "Animals and other organisms\n",
      "Human research participants\n",
      "Clinical dataMethods\n",
      "n/a Involved in the study\n",
      "ChIP-seq\n",
      "Flow cytometry\n",
      "MRI-based neuroimaging\n",
      "For null hypothesis testing, the test statistic (e.g. F, t, r) with confidence intervals, effect sizes, degrees of freedom and P value noted \n",
      "Give P values as exact values whenever suitable.\n",
      "For Bayesian analysis, information on the choice of priors and Markov chain Monte Carlo settings\n",
      "For hierarchical and complex designs, identification of the appropriate level for tests and full reporting of outcomes\n",
      "Estimates of effect sizes (e.g. Cohen's d, Pearson's r), indicating how they were calculated\n",
      "Our web collection on statistics for biologists  contains articles on many of the points above.\n",
      "Software and code\n",
      "Policy information about availability of computer code\n",
      "Data collection Data was collected using the publicly available version of StarCraft II (versions 4.8.2 to 4.10), developed by Blizzard Enterta inment. \n",
      "Data analysis We used the open source environment to interact with the game of StarCraft II, provided by Blizzard and DeepMind (https://githu b.com/\n",
      "deepmind/pysc2), using the game version 4.10. The networks used the TensorFlow 1.0 library with custom extensions. Analysis was  \n",
      "performed with custom code written in Python 2.7. We additionally provide pseudocode for all algorithms described in the paper.\n",
      "For manuscripts utilizing custom algorithms or software that are central to the research but not yet described in published lit erature, software must be made available to editors/reviewers. \n",
      "We strongly encourage code deposition in a community repository (e.g. GitHub). See the Nature Research  guidelines for submitting code & software  for further information.\n",
      "Data\n",
      "Policy information about availability of data\n",
      "All manuscripts must include a data availability statement . This statement should provide the following information, where applicable: \n",
      "- Accession codes, unique identifiers, or web links for publicly available datasets \n",
      "- A list of figures that have associated raw data \n",
      "- A description of any restrictions on data availability\n",
      "We did provide both the raw data used in the paper from the online experiment, and all the evaluation games played in the StarC raft II standard Replay format. The \n",
      "dataset containing all the replays used for imitation learning are distributed by Blizzard using a specific API: https://github .com/Blizzard/s2client-proto2 nature research  |  reporting summary October 2018Field-specific reporting\n",
      "Please select the one below that is the best fit for your research. If you are not sure, read the appropriate sections before m aking your selection.\n",
      "Life sciences Behavioural & social sciences  Ecological, evolutionary & environmental sciences\n",
      "For a reference copy of the document with all sections, see nature.com/documents/nr-reporting-summary-flat.pdf\n",
      "Life sciences study design\n",
      "All studies must disclose on these points even when the disclosure is negative.\n",
      "Sample size To study our agents performance, we played a total of 360 games online against the population of players that play StarCraft II  in the \n",
      "European servers. The sample size was determined with consultation with Blizzard and professional players, who deemed that 60 g ames \n",
      "would be sufficient to estimate performance of a new professional level player reliably with low uncertainty (less than 50 MMR) . We did play \n",
      "90 games total, per race, plus 30, per race, for supervised agents. For the league analysis we used around 130,000,000 full gam es of agent vs \n",
      "agent, and for ablations, we used around 20,000,000 games.\n",
      "Data exclusions No data was excluded from the study.\n",
      "Replication Because of the nature of the game, we did perform three independent experiments, using three distinct races. From the total of 9 runs, we \n",
      "did not observe any significant deviation, and thus we reproduced the intended conditions of the experiment ourselves. Because we played \n",
      "anonymously, reproducing the same conditions in future studies should be relatively easy, assuming care is taken to remain anon ymous.\n",
      "(Extended Data Fig. 8), where the pursuit of the mean win rate might \n",
      "lead to policies that are easy to exploit. This scheme is used as the \n",
      "default weighting of PFSP. Consequently, on the theoretical side, one \n",
      "can view fhard as a form of smooth approximation of max–min optimiza -\n",
      "tion, as opposed to max–avg, which is imposed by FSP. In particular, \n",
      "this helps with integrating information from exploits, as these are \n",
      "strong but rare counter strategies, and a uniform mixture would be \n",
      "able to just ignore them (Extended Data Fig. 5).\n",
      "Only playing against the hardest opponents can waste games against \n",
      "much stronger opponents, so PFSP also uses an alternative curriculum, \n",
      "fvar(x) = x(1 −  x), where the agent preferentially plays against opponents \n",
      "around its own level. We use this curriculum for main exploiters and \n",
      "struggling main agents.\n",
      "Populating the league. During training we used three agent types \n",
      "that differ only in the distribution of opponents they train against, \n",
      "when they are snapshotted to create a new player, and the probability of resetting to the supervised parameters.\n",
      "Main agents are trained with a proportion of 35% SP, 50% PFSP  \n",
      "against all past players in the league, and an additional 15% of PFSP \n",
      "matches against forgotten main players the agent can no longer beat \n",
      "and past main exploiters. If there are no forgotten players or strong \n",
      "exploiters, the 15% is used for self-play instead. Every 2 × 109 steps, a \n",
      "copy of the agent is added as a new player to the league. Main agents \n",
      "never reset.\n",
      "League exploiters are trained using PFSP and their frozen copies are \n",
      "added to the league when they defeat all players in the league in more \n",
      "than 70% of games, or after a timeout of 2 × 109 steps. At this point there \n",
      "is a 25% probability that the agent is reset to the supervised parameters. \n",
      "The intuition is that league exploiters identify global blind spots in the \n",
      "league (strategies that no player in the league can beat, but that are not \n",
      "necessarily robust themselves).Main exploiters play against main agents. Half of the time, and if the \n",
      "current probability of winning is lower than 20%, exploiters use PFSP \n",
      "with fvar weighting over players created by the main agents. This forms \n",
      "a curriculum that facilitates learning. Otherwise there is enough learn -\n",
      "ing signal and it plays against the current main agents. These agents \n",
      "are added to the league whenever all three main agents are defeated \n",
      "in more than 70% of games, or after a timeout of 4 × 109 steps. They \n",
      "are then reset to the supervised parameters. Main exploiters identify \n",
      "weaknesses of main agents, and consequently make them more robust.\n",
      "For more details refer to the Supplementary Data, Pseudocode.\n",
      "Infrastructure\n",
      "In order to train the league, we run a large number of StarCraft II \n",
      "matches in parallel and update the parameters of the agents on the \n",
      "basis of data from those games. To manage this, we developed a highly \n",
      "scalable training setup with different types of distributed workers.\n",
      "For every training agent in the league, we run 16,000 concurrent \n",
      "StarCraft II matches and 16 actor tasks (each using a TPU v3 device \n",
      "with eight TPU cores23) to perform inference. The game instances pro -\n",
      "gress asynchronously on preemptible CPUs (roughly equivalent to 150 \n",
      "processors with 28 physical cores each), but requests for agent steps \n",
      "are batched together dynamically to make efficient use of the TPU. \n",
      "Using TPUs for batched inference provides large efficiency gains over \n",
      "previous work14,29.\n",
      "Actors send sequences of observations, actions, and rewards over \n",
      "the network to a central 128-core TPU learner worker, which updates \n",
      "the parameters of the training agent. The received data are buffered in \n",
      "memory and replayed twice. The learner worker performs large-batch \n",
      "synchronous updates. Each TPU core processes a mini-batch of four \n",
      "sequences, for a total batch size of 512. The learner processes about \n",
      "50,000 agent steps per second. The actors update their copy of the\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Expert\n",
      "\u001b[0m\n",
      "\u001b[33mExpert\u001b[0m (to chat_manager):\n",
      "\n",
      "{\n",
      "    \"question1\": {\n",
      "        \"question\": \"Which antibody is often used as a control in cell line experiments due to its ubiquitous expression in eukaryotic cells?\",\n",
      "        \"correct_answer\": \"GAPDH\",\n",
      "        \"distractors\": [\"Tubulin\", \"Actin\", \"Myc\", \"Hemoglobin\"],\n",
      "        \"skills\": [\"General knowledge\"],\n",
      "        \"domains\": [\"biology\"],\n",
      "        \"difficulty\": \"hard\",\n",
      "        \"doi\": \"doi.org/10.1038/nature12345\",\n",
      "        \"author\": {\n",
      "            \"name\": \"Jose A. Tandoc\",\n",
      "            \"affiliation\": \"Argonne\",\n",
      "            \"position\": \"Student\",\n",
      "            \"orcid\": \"NA\"\n",
      "        },\n",
      "        \"support\": \"\",\n",
      "        \"comments\": \"generated question\"\n",
      "    },\n",
      "    \"question2\": {\n",
      "        \"question\": \"In a Bayesian statistical framework, what is the term used to describe the initial distributions input into the model prior to incorporating observed data?\",\n",
      "        \"correct_answer\": \"Priors\",\n",
      "        \"distractors\": [\"Posterior\", \"Likelihood\", \"Conjugate\", \"Monte Carlo\"],\n",
      "        \"skills\": [\"General knowledge\", \"Understanding identifiers/notation\"],\n",
      "        \"domains\": [\"mathematics\"],\n",
      "        \"difficulty\": \"hard\",\n",
      "        \"doi\": \"doi.org/10.1038/nature12345\",\n",
      "        \"author\": {\n",
      "            \"name\": \"Jose A. Tandoc\",\n",
      "            \"affiliation\": \"Argonne\",\n",
      "            \"position\": \"Student\",\n",
      "            \"orcid\": \"NA\"\n",
      "        },\n",
      "        \"support\": \"\",\n",
      "        \"comments\": \"generated question\"\n",
      "    },\n",
      "    \"question3\": {\n",
      "        \"question\": \"What is the primary computational infrastructure used to run parallel instances of gameplay in the context of training sophisticated game-playing AI?\",\n",
      "        \"correct_answer\": \"TPUs\",\n",
      "        \"distractors\": [\"GPUs\", \"CPUs\", \"ASICs\", \"FPGAs\"],\n",
      "        \"skills\": [\"General knowledge\"],\n",
      "        \"domains\": [\"computer science\"],\n",
      "        \"difficulty\": \"hard\",\n",
      "        \"doi\": \"doi.org/10.1038/nature12345\",\n",
      "        \"author\": {\n",
      "            \"name\": \"Jose A. Tandoc\",\n",
      "            \"affiliation\": \"Argonne\",\n",
      "            \"position\": \"Student\",\n",
      "            \"orcid\": \"NA\"\n",
      "        },\n",
      "        \"support\": \"\",\n",
      "        \"comments\": \"generated question\"\n",
      "    }\n",
      "}\n",
      " \n",
      " \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: question_generation_automator\n",
      "\u001b[0m\n",
      "\u001b[33mquestion_generation_automator\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Suggested tool call (call_KH8Gog4MPwxIfCeSx66IleBo): add_questions *****\u001b[0m\n",
      "Arguments: \n",
      "{\n",
      "  \"question1\": {\n",
      "    \"question\": \"Which antibody is often used as a control in cell line experiments due to its ubiquitous expression in eukaryotic cells?\",\n",
      "    \"correct_answer\": \"GAPDH\",\n",
      "    \"distractors\": [\"Tubulin\", \"Actin\", \"Myc\", \"Hemoglobin\"],\n",
      "    \"skills\": [\"General knowledge\"],\n",
      "    \"domains\": [\"biology\"],\n",
      "    \"difficulty\": \"hard\",\n",
      "    \"doi\": \"doi.org/10.1038/nature12345\",\n",
      "    \"author\": {\n",
      "      \"name\": \"Jose A. Tandoc\",\n",
      "      \"affiliation\": \"Argonne\",\n",
      "      \"position\": \"Student\",\n",
      "      \"orcid\": \"NA\"\n",
      "    },\n",
      "    \"support\": \"\",\n",
      "    \"comments\": \"generated question\"\n",
      "  },\n",
      "  \"question2\": {\n",
      "    \"question\": \"In a Bayesian statistical framework, what is the term used to describe the initial distributions input into the model prior to incorporating observed data?\",\n",
      "    \"correct_answer\": \"Priors\",\n",
      "    \"distractors\": [\"Posterior\", \"Likelihood\", \"Conjugate\", \"Monte Carlo\"],\n",
      "    \"skills\": [\"General knowledge\", \"Understanding identifiers/notation\"],\n",
      "    \"domains\": [\"mathematics\"],\n",
      "    \"difficulty\": \"hard\",\n",
      "    \"doi\": \"doi.org/10.1038/nature12345\",\n",
      "    \"author\": {\n",
      "      \"name\": \"Jose A. Tandoc\",\n",
      "      \"affiliation\": \"Argonne\",\n",
      "      \"position\": \"Student\",\n",
      "      \"orcid\": \"NA\"\n",
      "    },\n",
      "    \"support\": \"\",\n",
      "    \"comments\": \"generated question\"\n",
      "  },\n",
      "  \"question3\": {\n",
      "    \"question\": \"What is the primary computational infrastructure used to run parallel instances of gameplay in the context of training sophisticated game-playing AI?\",\n",
      "    \"correct_answer\": \"TPUs\",\n",
      "    \"distractors\": [\"GPUs\", \"CPUs\", \"ASICs\", \"FPGAs\"],\n",
      "    \"skills\": [\"General knowledge\"],\n",
      "    \"domains\": [\"computer science\"],\n",
      "    \"difficulty\": \"hard\",\n",
      "    \"doi\": \"doi.org/10.1038/nature12345\",\n",
      "    \"author\": {\n",
      "      \"name\": \"Jose A. Tandoc\",\n",
      "      \"affiliation\": \"Argonne\",\n",
      "      \"position\": \"Student\",\n",
      "      \"orcid\": \"NA\"\n",
      "    },\n",
      "    \"support\": \"\",\n",
      "    \"comments\": \"generated question\"\n",
      "  }\n",
      "}\n",
      "\u001b[32m******************************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: User\n",
      "\u001b[0m\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION add_questions...\u001b[0m\n",
      "\u001b[33mUser\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[33mUser\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Response from calling tool (call_KH8Gog4MPwxIfCeSx66IleBo) *****\u001b[0m\n",
      "Finished\n",
      "\u001b[32m**********************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for idx, doc in enumerate(docs[:1]):\n",
    "    retrieval_assistant = initiate_RAG_agent([doc], f'doc{idx}')\n",
    "    def state_transition(last_speaker, groupchat):\n",
    "        messages = groupchat.messages\n",
    "        if last_speaker is retrieval_assistant:\n",
    "            return expert\n",
    "        elif last_speaker is expert:\n",
    "            if \"UPDATE CONTEXT\" in messages[-1][\"content\"]:\n",
    "                return retrieval_assistant\n",
    "            return automator\n",
    "        # elif last_speaker is format_verifier:\n",
    "        #     if \"VALID\" in messages[-1][\"content\"]:\n",
    "        #         return generality_verifier\n",
    "        #     else:\n",
    "        #         return expert\n",
    "        # elif last_speaker is generality_verifier:\n",
    "        #     if \"VALID\" in messages[-1][\"content\"]:\n",
    "        #         return automator \n",
    "        #     else:\n",
    "        #         return expert\n",
    "        elif last_speaker is automator:\n",
    "            return user_proxy\n",
    "        elif last_speaker is user_proxy:\n",
    "            return None\n",
    "    def rag_chat(retrieval_assistant):\n",
    "        _reset_agents(retrieval_assistant)\n",
    "        groupchat = autogen.GroupChat(\n",
    "            agents=[retrieval_assistant, expert, automator, user_proxy], messages=[], max_round=20,\n",
    "            speaker_selection_method=state_transition,\n",
    "            send_introductions=True, # Provides information on each agent in the group chat to the manager.\n",
    "        )\n",
    "        \n",
    "        manager = autogen.GroupChatManager(groupchat=groupchat, llm_config={\n",
    "            \"config_list\": config_list, \n",
    "            \"cache_seed\": None, # Ensures differing responses\n",
    "            \"timeout\": 600,\n",
    "            \"seed\": 42,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Start chatting with retrieval_assistant as this is the user proxy agent.\n",
    "        retrieval_assistant.initiate_chat(\n",
    "            manager,\n",
    "            message=retrieval_assistant.message_generator,\n",
    "            problem=problem,\n",
    "            n_results=3,\n",
    "        )\n",
    "    rag_chat(retrieval_assistant)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [500]>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'Which antibody is often used as a control in cell line experiments due to its ubiquitous expression in eukaryotic cells?',\n",
       " 'correct_answer': 'GAPDH',\n",
       " 'distractors': \"['Tubulin', 'Actin', 'Myc', 'Hemoglobin']\",\n",
       " 'skills': \"['General knowledge']\",\n",
       " 'domains': \"['biology']\",\n",
       " 'difficulty': 'hard',\n",
       " 'doi': 'doi.org/10.1038/nature12345',\n",
       " 'author': \"{'name': 'Jose A. Tandoc', 'affiliation': 'Argonne', 'position': 'Student', 'orcid': 'NA'}\",\n",
       " 'support': nan,\n",
       " 'comments': 'generated question'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from json import loads, dumps\n",
    "import requests\n",
    "import pandas as pd\n",
    "df = pd.read_csv(r\"generatedQuestions/generated_questions.csv\", index_col=False)\n",
    "length = df.shape[0]\n",
    "headers = {\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "TEST_URL = 'https://web.cels.anl.gov/projects/auroragptquestions/api/test_question'\n",
    "SUBMIT_URL = 'https://web.cels.anl.gov/projects/auroragptquestions/api/question'\n",
    "for idx in range(1):\n",
    "    data = dumps(df.iloc[idx].to_dict())\n",
    "    response = requests.post(TEST_URL, headers=headers, data=data)\n",
    "    print(response)\n",
    "df.iloc[idx].to_dict()\n",
    "# for idx in range(length):\n",
    "#     data = df.iloc[idx].to_json()\n",
    "#     response = requests.post(SUBMIT_URL, headers=headers, data=data)\n",
    "#     print(response)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\judoc\\AppData\\Local\\Temp\\ipykernel_6932\\2756236830.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['doi'] = '1234TEST'\n",
      "C:\\Users\\judoc\\AppData\\Local\\Temp\\ipykernel_6932\\2756236830.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['distractors'] = ast.literal_eval(data[\"distractors\"])\n",
      "C:\\Users\\judoc\\AppData\\Local\\Temp\\ipykernel_6932\\2756236830.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['skills'] = ast.literal_eval(data[\"skills\"])\n",
      "C:\\Users\\judoc\\AppData\\Local\\Temp\\ipykernel_6932\\2756236830.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['domains'] = ast.literal_eval(data[\"domains\"])\n",
      "C:\\Users\\judoc\\AppData\\Local\\Temp\\ipykernel_6932\\2756236830.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['author'] = ast.literal_eval(data[\"author\"])\n",
      "C:\\Users\\judoc\\AppData\\Local\\Temp\\ipykernel_6932\\2756236830.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['support'] = \"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\"question\":\"In a Bayesian statistical framework, what is the term used to describe the initial distributions input into the model prior to incorporating observed data?\",\"correct_answer\":\"Priors\",\"distractors\":[\"Posterior\",\"Likelihood\",\"Conjugate\",\"Monte Carlo\"],\"skills\":[\"General knowledge\",\"Understanding identifiers\\\\/notation\"],\"domains\":[\"mathematics\"],\"difficulty\":\"hard\",\"doi\":\"1234TEST\",\"author\":{\"name\":\"Jose A. Tandoc\",\"affiliation\":\"Argonne\",\"position\":\"Student\",\"orcid\":\"NA\"},\"support\":\"\",\"comments\":\"generated question\"}'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "data = df.iloc[1]\n",
    "data['doi'] = '1234TEST'\n",
    "data['distractors'] = ast.literal_eval(data[\"distractors\"])\n",
    "data['skills'] = ast.literal_eval(data[\"skills\"])\n",
    "data['domains'] = ast.literal_eval(data[\"domains\"])\n",
    "data['author'] = ast.literal_eval(data[\"author\"])\n",
    "data['support'] = \"\"\n",
    "data.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"question\":\"In a Bayesian statistical framework, what is the term used to describe the initial distributions input into the model prior to incorporating observed data?\",\"correct_answer\":\"Priors\",\"distractors\":[\"Posterior\",\"Likelihood\",\"Conjugate\",\"Monte Carlo\"],\"skills\":[\"General knowledge\",\"Understanding identifiers\\\\/notation\"],\"domains\":[\"mathematics\"],\"difficulty\":\"hard\",\"doi\":\"1234TEST\",\"author\":\"{\"name\": \"Jose A. Tandoc\", \"affiliation\": \"Argonne\", \"position\": \"Student\", \"orcid\": \"NA\"}\",\"support\":\"\",\"comments\":\"generated question\"}'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA = data.to_json()\n",
    "response = requests.post(TEST_URL, headers=headers, data=DATA)\n",
    "DATA.replace(\"'\", \"\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_proxy = autogen.ConversableAgent(\n",
    "#     name=\"User\",\n",
    "#     llm_config=False,\n",
    "#     is_termination_msg=lambda msg: msg.get(\"content\") is not None and \"TERMINATE\" in msg[\"content\"],\n",
    "#     human_input_mode=\"NEVER\",\n",
    "# )\n",
    "\n",
    "# assistant = autogen.ConversableAgent(\n",
    "#     name=\"Assistant\",\n",
    "#     system_message=\"You are a helpful AI assistant. \"\n",
    "#     \"You help with JSON Formatting\"\n",
    "#     \"Return 'TERMINATE' when the task is done.\",\n",
    "#     llm_config=llm_config,\n",
    "# )\n",
    "# test = []\n",
    "# def json_return(first_name: str, last_name: str, email: str) -> Dict:\n",
    "#     form = {\n",
    "#         'first_name': first_name,\n",
    "#         'last_name': last_name,\n",
    "#         'email': email,\n",
    "#     }\n",
    "#     test.append(form)\n",
    "#     return form\n",
    "\n",
    "# register_function(\n",
    "#     json_return,\n",
    "#     caller=assistant,  # The assistant agent can suggest calls to the calculator.\n",
    "#     executor=user_proxy,  # The user proxy agent can execute the calculator calls.\n",
    "#     name=\"json_return\",  # By default, the function name is used as the tool name.\n",
    "#     description=\"A json object returner\",  # A description of the tool.\n",
    "# )\n",
    "# form = {\n",
    "#     'first_name': 'first name',\n",
    "#     'last_name': 'last name',\n",
    "#     'email': 'email',\n",
    "# }\n",
    "# chat_result = user_proxy.initiate_chat(assistant, message= f'''Produce a json object using the following format: {form} given this information: Alec Tandoc, metandoc@gmail.com''', max_turns=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
